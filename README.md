# awesome-trustworthy-LLMs
[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/hee9joon/Awesome-Diffusion-Models) 
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![Made With Love](https://img.shields.io/badge/Made%20With-Love-red.svg)](https://github.com/chetanraj/awesome-github-badges)

This repository contains a collection of resources and papers on *** trustworthy Large Language Models ***.

## Contents
- [Resources](#resources)
- [Papers](#papers)
  - [Survey](#survey)
  - [Explainability](#explainability)  
  - [Security](#security)
  - [Robustness](#robustness)
  - [Privacy](#privacy)
  - [Fairness](#fairness)
- 
# Resources
## Introductory Posts
**GPT-4 is OpenAI’s most advanced system, producing safer and more useful responses.** \
*OpenAI* \
[[Website](https://openai.com/product/gpt-4)] \
14 Mar 2023

# Papers

## Survey

**A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity** \
*Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, Quyet V. Do, Yan Xu, Pascale Fung* \
28 Feb 2023. [[Paper](https://arxiv.org/abs/2302.04023)] \

## Explainability

## Security

**Exploiting Programmatic Behavior of LLMs: Dual-Use Through Standard Security Attacks** \
*Daniel Kang, Xuechen Li, Ion Stoica, Carlos Guestrin, Matei Zaharia, Tatsunori Hashimoto* \
11 Feb 2023. [[Paper](https://arxiv.org/abs/2302.05733)] \



**More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models** \
*Kai Greshake, Sahar Abdelnabi, Shailesh Mishra, Christoph Endres, Thorsten Holz, Mario Fritz* \
23 Feb 2023. [[Paper](https://arxiv.org/abs/2302.12173)] \


**Ignore Previous Prompt: Attack Techniques For Language Models** \
*Fábio Perez, Ian Ribeiro*
17 Nov 2022 [[Paper](https://arxiv.org/abs/2211.09527)]
## Robustness

## Privacy

## Fairness

